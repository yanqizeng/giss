---
title: "Name: Yanqi Zeng"
author: 
- |
    | Student number: 21093408
date: "`r format(Sys.time(), '%X, %d %B, %Y')`"
output: html_document
---

# Originality declaration

I, [**Yanqi Zeng**], confirm that the work presented in this assessment is my own. Where information has been derived from other sources, I confirm that this has been indicated in the work.

date: `r format(Sys.time(), '%d %B, %Y')`

# Response

## Project Scope

### Project Research Background


### Research Question and Null Hypothesis

-   Research question:哪些因素可能导致2019年整个纽约的驱逐事件发生变化？

-   Null Hypothesis: 这和商业地区的密度没有关系

### Data

-   Data list:
-   Data type:
-   Variables of interest
-   Attribute table
-   Unique join field
-   Coordinate reference system:
-   Source
-   Data collectors
-   Collection methodology
-   Any missing data

### Limitations

### Workflow


```{r warning=FALSE, message=FALSE}
library(tidyverse)
library(tmap)
library(rgdal)
library(broom)
library(mapview)
library(crosstalk)
library(sf)
library(sp)
library(spData)
library(spdep)
library(carData)
library(car)
library(fs)
library(janitor)
library(spatstat)
library(here)
library(RColorBrewer)
library(tmaptools)

```

## Data Loading

Use the st_read() function to read in the .shp file from my project folder.

EXPLAIN - Get census tract shapefile.
```{r Read in data}
census_tract_shape <- st_read("Question_02/Census 2020_ Tracts for San Francisco/geo_export_3454aae8-153a-4086-b349-4c52fbeb2b02.shp") %>%
  st_transform(., crs=7131)

```

Read in the .csv file from my project folder.

EXPLAIN - Get graffiti points.
```{r Read in data}
graffiti_points <- read_csv("Question_02/Graffiti.csv")

```

Checking the variable type.

EXPLAIN - Check to ensure that the variable type is correct.

```{r Data type}
Datatypelist <- graffiti_points %>% 
  summarise_all(class) %>%
  pivot_longer(everything(), 
               names_to="All_variables", 
               values_to="Variable_class")

Datatypelist
```

## Data Wrangling

Create new columns.

EXPLAIN - Divide the data set Point column into two columns, longitude and latitude. Preparing for the next analysis.

```{r Create new columns}
graffiti_points_2<-graffiti_points%>%
  separate(., Point, c("latitude", "longitude"), sep = ",")
  
graffiti_points_2$latitude<-parse_number(graffiti_points_2$latitude) ## leading $ and grouping character , ignored
graffiti_points_2$longitude<-parse_number(graffiti_points_2$longitude) ## leading $ and grouping character , ignored

```

First, filter the csv by Longitude = 0 and Latitude = 0. Second, convert csv to sf objects the map based on crs = 4326.

EXPLAIN - The purpose of this step is to convert the csv to points for later spatial analysis. First filter the csv invalid data by setting conditions, this ensures that the csv is converted effectively. Then make sure they are in WGS84, the coordinate reference system (CRS) used for 2D is 4326.

```{r convert csv to sf objects}
graffiti_points_3<- graffiti_points_2%>%
  filter(latitude !=	0 )%>%
  filter(longitude != 0)%>%
  st_as_sf(., coords = c("longitude", "latitude"), 
                   crs = 4326)
```

First use string testing to find the 2019 data in the Closed column, based on this, only the 2019 data related to commercial is retained.

EXPLAIN - Step-by-step processing of large data sets based on research questions and null hypotheses. Only the data relevant to the research question is retained, which facilitates the spatial next analysis.

OUTPUT - This has reduced it to 64902 points.

```{r Filter points}
graffiti_points_4<- graffiti_points_3%>%
filter(str_detect(Closed, "2019"))%>%
  
  st_transform(., crs=7131)

summary(graffiti_points_4)
```

Spatial filter points within the san fran polygon (sf object).

EXPLAIN - Points outside the region can cause problems in the next analysis. When checking the data, if there are points that are not in the region, the problem can be dealt with by spatial subsetting, spatial clipping, etc.

```{r Filter points}
graffiti_within <- graffiti_points_4[census_tract_shape, ,op=st_intersects]
```

Plot the graffiti points in the study site.

EXPLAIN - First, plot the graffiti points to check that other countries do not have points, and that the longitude and latitude are correct. Second, have a general understanding of the distribution of graffiti points.

```{r Plot}
tmap_mode("plot")
tm_shape(census_tract_shape) +
  tm_polygons(col = NA, alpha = 0.5) +
tm_shape(graffiti_points_4) +
  tm_dots(col = "blue")

```





At this stage we need to make density of points per spatial unit. I used to do that with a spatial join! However, reference the issue with this that was pointed out to me in 2022 by a student. 

```{r, eval=FALSE}

  points_sf_joined <- census_tract_shape%>%
    st_join(graffiti_points_4)%>%
    add_count(geoid10)%>%
    janitor::clean_names()%>%
    #calculate area
    mutate(area=st_area(.))%>%
    #then density of the points per ward
    mutate(density=n/area)%>%
    dplyr::select(geoid10 , neighborhood, density)%>%
    group_by(geoid10) %>%         
  summarise(geoid10 = first(geoid10),
          neighborhood= first(neighborhood),
          density= first(density))


```

So....we use st_intersects...


```{r}

points_sf_joined<-shape%>%
  mutate(n = lengths(st_intersects(., graffiti4)))%>%
  janitor::clean_names()%>%
    #calculate area
    mutate(area=st_area(.))%>%
    #then density of the points per ward
    mutate(density=n/area)

```

Now i will read in some census data...

Another way to explore the census data is to use the explorer that lists some relevant data and the tables they are in...https://data.census.gov/profile/Census_Tract_308,_San_Francisco_County,_California?g=1400000US06075030800 

Here i have downloaded the S2701 changes in health insurance data: https://data.census.gov/table?q=SELECTED+CHARACTERISTICS+OF+HEALTH+INSURANCE+COVERAGE+IN+THE+UNITED+STATES&t=Health&g=0400000US06$1400000&tid=ACSST5Y2020.S2701

Read it in...health data ends in 819 folder

```{r}
census_health <- read_csv("Data_graffiti/ACSST5Y2020.S2701_2022-12-06T131819/ACSST5Y2020.S2701-Data.csv", skip=1)
 
  
 census_health2 <- census_health%>%
  clean_names()
 
```


A very apparent problem is that there isn't a common column to join this data...

Within this data there is a column called "estimate_percent_insured_civilian_noninstitutionalized_population" which might be useful...

Select the column then join the data to our main sf file...remember i am trying to model the density of graffiti here...

```{r}

census_health3 <-census_health2 %>%
  select(geography, geographic_area_name, estimate_percent_insured_civilian_noninstitutionalized_population)%>%
  mutate(tract = str_sub(geography, start = 10, end=20))



points_sf_joined_join_health_insur <- points_sf_joined %>%
  left_join(., census_health3,
            by=c("geoid" = "tract"))

```

The census tracts that are not joined have low or zero population as they are in the sea!

What other data can we join here....we should read in all our data together and then join in, but now let's read in income and join...

I personally find the best way to explore the columns is with the dollar. In the console type `census_income$` then the column names should appear.

Now there is lots of data here, i frist tried to use median data estaimte, but a few more missing values appeared - they weren't an error of the join as i checked the original data and it contained a -. I've been unable to find what this means, i assume missing data. However, mean household income has all the values that i need (aside from the same values missing for the tracts in the sea we saw before.)

After much searching i found this info, where the dash means insufficient sample observations: https://www.census.gov/data/developers/data-sets/acs-1year/notes-on-acs-estimate-and-annotation-values.html

Note these are 5 year estimates: averages taken over 5 years - https://www.census.gov/programs-surveys/acs/guidance/estimates.html 

Income ends in 746 folder

```{r}
census_income <- read_csv("Data_graffiti/ACSST5Y2020.S1901_2022-12-07T041746/ACSST5Y2020.S1901-Data.csv", skip=1)
 
  
census_income2 <- census_income%>%
  clean_names()
 

census_income3 <-census_income2 %>%
  select(geography, geographic_area_name, estimate_households_mean_income_dollars, estimate_households_median_income_dollars, estimate_households_total)%>%
  mutate(tract = str_sub(geography, start = 10, end=20))
 
 
```

Join again!

```{r}
points_sf_joined_join_health_insur_income <- points_sf_joined_join_health_insur %>%
  left_join(., census_income3,
            by=c("geoid" = "tract"))

```

Census guide: https://www.census.gov/programs-surveys/acs/library/handbooks/general.html

Excellent book covering regression with US census data: https://walker-data.com/census-r/
